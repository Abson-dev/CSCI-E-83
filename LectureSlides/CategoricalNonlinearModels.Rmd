---
title: "Models Categorical Variables and Nonlinear Response"
author: "Steve Elston"
date: "10/27/2022"
output:
  slidy_presentation: default
  pdf_document: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_python("/usr/bin/python3")
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
#knitr::knit_engines$set(python = reticulate::eng_python)
```



## Review    

Linear models are a flexible and widely used class of models   

- Fit model coefficients by **least squares** estimation   

- Can use many types of predictor variables   

- We prefer the simplest model that does a reasonable job   
   - The principle of **Occam's razor**  

- Must consider the **bias-variance trade-off**  


## Review   

When evaluating any machine learning model consider **all evaluation methods available**    

- No one method best all of the time    
  - Homoskedastic Normally distributed residuals   
  - Reasonable values $R^2$, RMSE, etc
  - Are the model coefficients all significant? 

- **Different methods highlight different problems** with your model     

- Don't forget to check that the **model must make sense** for your application! 


## Review      

 Representation of machine learning models      
 
 - The key representation is the model matrix      
    - Column of 1s for intercept      
    - Columns of feature or predictor values   
 
 $$
A = 
\begin{bmatrix}
1, x_{1,1}, x_{1,2}, \ldots, x_{1,p}\\
1, x_{2,1}, x_{2,2}, \ldots, x_{2,p}\\
1, x_{3,1}, x_{3,2}, \ldots, x_{3,p}\\
\vdots,\ \vdots,\ \vdots,\ \vdots,\ \vdots\\
1, x_{n,1}, x_{n,2}, \ldots, x_{n,p}
\end{bmatrix}
$$
 
 - There are two standards for signatures of ML functions    
    - A model matrix $X$ (exogenous-features) and label array $Y$ (dependent-endogenous) - Scikit-learn and base Statsmodels   
    - A data frame with all features (predictors) and label (dependent) columns plus a model formula - Statsmodels formula and R   



## Review    

There are a number of assumptions in linear models that you overlook at your peril! 

- The feature or predictor variables should be **independent** of one another      
   - This is rarely true in practice   
   - **Multi-collinearity** between features makes the model **under-determined**   

- We assume that numeric features or predictors have **zero mean** and about the **same scale**      
   - We do not want to bias the estimation of regression coefficients with predictors that do not have a 0 mean   
   - We do not want to have predictors with a large numeric range dominate training   
   - Example: income is in the range of 10s or 100s of thousands and age is in the range of 10s, but apriori income is no more important than age as a predictor  
   
- Values of each predictor or feature should be iid      
   - If variance changes with sample, the optimal value of the coefficient could not be constant    
   - If there **serial correlation** in the predictor values, the iid assumption is violated - but can account for this such as in time series models   
   


## Review       

Scaling of features is required for many machine learning models      

- Several commonly used approaches      
   - **Z-score** scaling results in features with zero mean and unit variance    
   - Use Z-score scaling for features approximately normally distributed   
   - **Min-max** scaling transforms feature values to range 0-1   
   - Use min-max scaling for features with truncated range of values   

- Effect on model coefficients   
   - Scaling changes model coefficients by the scale factor applied   
   - Can re-scale (unscale) model coefficients before processing unknown cases    
   - Or use **same scaling** for unknown feature values   
   
- When coding categorical variables as binary dummy variables no need to scale - already in range [0-1]    


## Introduction  

- Working with categorical variables    
   - One-hot encoding    
   - Working with contrasts    
   - Effects and adjustments    

- Building models with nonlinear or non-Normal response   
  - Use generalized linear model for nonlinear response          
  - Link function transforms to nonlinear model to linear model       
  - Evaluating Binomial response models   
  - Compare model performance with deviance   
  - Poisson regression   


## Working with Categorical Variables 

Linear models, like nearly all machine learning models, use numeric features    

- How can categorical variables be used in linear models?    

- Need to transform categories to numeric variables with **one hot encoding**      
   - Each category becomes a binary **dummy variable**, encoded [0,1]  
   - Only one dummy variable has nonzero value - encodes the category   
   - n categories represented by n-1 dummy variables; all 0s encodes one level    
   
- Binary variables are an exception    
   - Represent with a single binary variable. [0,1] values


## Working with Categorical Variables  

Example: Consider a data set with categorical variables

```{python, echo=FALSE}
import pandas as pd
import numpy as np
import numpy.random as nr
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import scipy.stats as ss  
from math import atan

test_scores = pd.read_csv('../data/hsb2.csv')#, index_col=0)
test_scores.head(10)
```

## Working with Categorical Variables  

Example: split the data into train and test subsets    

```{python}
nr.seed(2345)
msk = nr.choice(test_scores.index, size = 120, replace=False)
test_scores_train = test_scores.iloc[msk,:]
print(test_scores_train.shape)
test_scores_test = test_scores.drop(msk, axis=0) 
print(test_scores_test.shape)
```




## Working with Categorical Variables  

Example: We can encode a categorical variable with the Python patsy package to get the X (model) and Y(label) arrays:     

```{python}
from patsy import dmatrices
Y, X = dmatrices("socst ~ C(ses, levels=[1,2,3])", data=test_scores)
print(X[:5])
print(Y[:5])
```


## Working with Categorical Variables  

Example: A simple linear model with one categorical variable       

```{python}
import statsmodels.formula.api as smf 
linear_model = smf.ols("socst ~ C(ses)", data=test_scores_train).fit()
linear_model.summary()
```


## Working with Categorical Variables  

Wait! What happened to the coefficient for the first level of ses?  

- The intercept is the **mean response** of the first level     

- The other coefficients are **contrasted** with respect to the mean of the first level.       
- Consider the following possible ways we can encode responses to a categorical variable - often called a **treatment**      
   - For $n$ treatments, there are mean responses $[ \mu_1, \mu_2, \ldots, \mu_n ]$   
   - The alternative encoding is a treatment with intercept, $I$, at $n - 1$ **contrasts**, $[ I, c_1, \ldots, c_{n-1}]$    
   
- The means and contrasts are related:    
   
$$\begin{bmatrix}
I\\
c_2\\
\vdots\\
c_n
\end{bmatrix} = 
\begin{bmatrix}
\mu_1\\
\mu_2 - \mu_1\\
\vdots\\
\mu_n - \mu_1
\end{bmatrix}$$   

## Working with Categorical Variables    

In a linear model we can sometimes relate the coefficient values to an effect size    

- Start with $n$ treatments $[t_1, t_2, \ldots, t_n ]$ with effect sizes, $[e_1, e_2, \ldots, e_n ]$     

- With **no intercept term** the means represent the effect sizes:   

$$\begin{bmatrix}
e_1\\
e_2\\
\vdots\\
e_n
\end{bmatrix} = 
\begin{bmatrix}
\mu_1\\
\mu_2\\
\vdots\\
\mu_n
\end{bmatrix}$$  

- With intercept term compute effect sizes using contrasts:  

$$\begin{bmatrix}
e_1\\
e_2\\
\vdots\\
e_n
\end{bmatrix} = 
\begin{bmatrix}
I\\
I + c_1\\
\vdots\\
I + c_{n-1}
\end{bmatrix}$$   
 
 
## Working with Categorical Variables    

In a linear model we can sometimes relate the coefficient values to an effect size    

- Assumes the treatments are orthogonal    
   - In other words, applied on at a time    
   - e.g. a case can only be in one category     
   
- Assumes that the model coefficients are statistically independent    
   - Coefficients are dependent in overfit model    
   
- Often need to **adjust** for other effects    
   - Other treatments   
   - Levels of other categorical variables    
   - Use **partial slope** of continuous variables  
   
- In other words **apply** with care!    
   - Don't over-interpret your model   
   - Conditions in real world hard to verify, particularly for observational data   
 

## Models with Nonlinear Response    

How do we deal with models that do not have nonlinear response variables?   

- Example: binary response variable, $[0,1]$, $Bin(\theta)$ distributed     
   - Probability parameter $\theta$
   - A binary classifier      
   
- Example: Intensity of an arrival process, $poisson(\lambda)$ response   
   - $\lambda$ is the average rate or **intensity** of a point process 
   - Estimate the parameter $\lambda$    
   
- Example: Categorical response variable for $n$ categories, $Multi(\pi_1, \pi_2, \ldots, \pi_n)$:    
   - $n$ category classifier
   - Response is probability probability for each category, $\Pi = [\pi_1, \pi_2, \ldots, \pi_n]$ 



## Models with Nonlinear Response    

The **generalized linear model (GLM)** is a framework for nonlinear response models   

- Nonlinear response is non-Normally distributed  
   
- For each distribution use a **link function** to transform to a linear model    
   - Linear model has Normally distributed response   
   - Link function transform nonlinear response to Normal distribution  

- To compute the nonlinear response  
   - Start with a linear model, OLS    
   - Transform response with **inverse link function**    
   - Works for all exponential family response distributions      
   
   
## The Generalized Linear Model   

Link functions are available for many distributions      


- Supported in [statsmodels](https://www.statsmodels.org/stable/glm.html)        

- Supported in [Scikit-Learn](https://scikit-learn.org/stable/modules/linear_model.html#generalized-linear-regression)     

- Examples: 
   - Gaussian, identity function    
   - Inverse Gaussian   
   - Binomial, logit function    
   - Multinomial  
   - Poisson    
   - Negative Binomial   
   - Gamma   
   - Tweedie   

## The Generalized Linear Model   

Start with a regression model for binary classification - **logistic regression**   

- Use Binomial distribution to model $y$ successes in $n$ trials    

$$y \sim Bi(n, \theta)$$

- But finding the best fit value of parameter $\theta$ directly is a nonlinear problem!   
- Instead, define a **link function**, known as the **logit function** for parameter $\lambda$     

$$\lambda = log \Bigg\{ \frac{\theta}{1-\theta} \Bigg\}$$

- After a bit of algebra we find the exponential relationship with $y$

$$y = n\ log(1+ e^\lambda)$$


## The Generalized Linear Model  

Formulate a linear regression problem using the link function      

$$\lambda = log \Bigg\{ \frac{\theta}{1-\theta} \Bigg\} = X \vec{b}$$    
for model matrix $X$ and coefficient vector $\vec{b}$

- Given estimate of $\lambda$, compute $\theta$    

$$\theta = \frac{1}{1 + e^\lambda} = \frac{1}{1 + e^{X \vec{b}}}$$

The **inverse link function** for Binomial response!


## The Generalized Linear Model  

Consider the example for a single feature, $x$     

- The linear model has only slope and intercept, $[ \beta_0, \beta_1]$ 

$$\lambda_i = log \Bigg\{ \frac{\theta_i}{1-\theta_i} \Bigg\} = \beta_0 + \beta_1 x_i$$      

and    

$$\theta_i = \frac{1}{1 + e^{\beta_0 + \beta_1 x_i}}$$


## Logistic Regression Model

What does the transformation function look like?    

$$y = \frac{1}{1 + e^\lambda}$$

```{python, echo=FALSE}
import pandas as pd
import numpy as np
import numpy.random as nr
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
import scipy.stats as ss  
from math import atan

test_scores = pd.read_csv('../data/hsb2.csv', index_col=0)
#test_scores.head(10)
```


```{python, echo=FALSE}
# Plot the logistic transformation function (f(x) above)
x_seq = np.linspace(-7, 7, 100)

def log_fun(x, center=0, scale=1):
    e = np.exp(-scale*(x-center))
    log_out = 1./(1. + e)
    return log_out

log_fun_vectorized = np.vectorize(log_fun)

log_y = log_fun_vectorized(x_seq)

fig, ax = plt.subplots(figsize=(4,3))
ax.plot(x_seq, log_y)
ax.set_title('Standard Logistic Function')
ax.set_xlabel('x')
ax.set_ylabel('y')
plt.grid()
plt.show()
```

- The response is bound in the range $[0,1]$

- We say the logistic transformation **squashes** the linear response $\lambda =X \vec{b}$ to binary, $[0,1]$   

- Can set a **decision threshold** for binary response    
   - Default $= 0.5$


## Evaluation of Classifiers   

How can we evaluate a classifier's accuracy? 

- Determine proportions of test cases which are classified as:     
   - True Positives (TP): Are positive and should be positive      
   - True Negatives (TN): Are negative and should be negative    
   - False Positives (FP): Classified as positive but are actually negative; **Type I errors**   
   - False Negatives (FN): Classified as negative but are actually positive; **Type II errors**   

- Organize these metrics into a **confusion matrix**      

|  | Classified Positive | Classified Negative |
| ---- | :---: | :---: |
|Positive | TP | FN |  
|Negative | FP | TN |



## Evaluation of Classifiers   


The other metrics are defined as follows:

- Accuracy = (TP + TN) / (TP + FP + TN + FN)      

- Selectivity or Precision = TP / (TP + FP)       
   - Precision is the fraction of the relevant class predictions are actually correct     
   
- Sensitivity or Recall = TP / (TP + FN)
   - Recall is the fraction of the relevant class were we able to predict    


- Is a trade-off between precision and recall     
   - Consider changing the decision threshold    
   - High threshold $\rightarrow$ higher recall, more false negatives   
   - Low threshold $\rightarrow$ higher precision, more false positives    

## Example of Logistic Regression    

How well can we predict the type of school given the test scores?     

```{python}
## Prep the data
test_scores['schtyp'] = np.subtract(test_scores['schtyp'], 1)
for col in ['read', 'write', 'math', 'science', 'socst']:
    test_scores[col] = np.divide(np.subtract(test_scores[col], np.mean(test_scores[col])), np.std(test_scores[col]))

## Fit the model
formula = 'schtyp ~ math'
logistic_reg_model = smf.glm(formula=formula, data=test_scores, family=sm.families.Binomial()).fit()

## score the results 
threshold=0.18
test_scores['predicted'] = logistic_reg_model.predict()
test_scores['score'] = [1 if x>threshold else 0 for x in test_scores['predicted']]

print(logistic_reg_model.summary())
```


## Example of Logistic Regression    

The data frame now looks like this with the predicted probability and the binary scores:

```{python}
test_scores.head(20)
```


## Example of Logistic Regression    

Now, evaluate the model - the classifier is almost useless - **no Kagle awards!**:   

```{python}
import sklearn.metrics as sklm  
def print_metrics(labels, scores):
    metrics = sklm.precision_recall_fscore_support(labels, scores)
    conf = sklm.confusion_matrix(labels, scores)
    print('                 Confusion matrix')
    print('                 Score positive    Score negative')
    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])
    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])
    print('')
    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))
    print(' ')
    print('           Positive      Negative')
    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])
    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])
    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])
    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])
    
print_metrics(test_scores['schtyp'], test_scores['score'])    
```


## Example of Logistic Regression     

How can we understand the cut-off value in terms of the CDF of the positive and negative cases?    

```{python, echo=FALSE}
fig, ax = plt.subplots(figsize=(4, 3)) # define axis
sns.ecdfplot(x='predicted', hue='schtyp', data=test_scores, ax=ax)
ax.set_ylabel('Cummulative probability')
ax.axvline(0.18, color='red', linestyle='dotted')
```

- Positive cases to the left of cut-off are Type II errors     
- Negative cases to the right of cut-off are Type I errors   
- Probability curves nearly the same = poor model   


## What is Deviance?

The significance of a GLM is expressed in terms of **deviance**     

- Deviance can be challenging to understand what deviance really means      

- Formally, deviance is the expected value of the ratio of one probability density function, $f_1(y)$ to a second probability density function, $f_2(y)$:

$$D\big[f_1(y),f_1(y) \Big] = 2 \int_y f_1(y) log \Bigg\{ \frac{f_1(y)}{f_2(y)} \Bigg\} dy$$

If $f_1(y) \rightarrow f_1(y)$, then:

$$log \Bigg\{
\frac{f_1(y)}{f_2(y)} \Bigg\} \rightarrow log(1) \rightarrow 0$$

And, $D\big[f_1(y),f_1(y) \Big] \rightarrow 0$


## What is Deviance? 

Deviance is a measure of the divergence between two distributions   

- Consider an easy to understand form of deviance for the Normal distribution    
   
- Model with Normally distributed response  
   - The mean squared error of a model is the deviance      
   - If two distribution are identical the deviance is 0    



## What is Deviance?

Deviance of a model can be evaluated using deviance with respect to a saturated model  

\begin{align}
D(y,\hat{\mu}) &= 2 \Big( log \big( p(y | \hat{\theta}_{S}) \big) - log \big( p(y | \hat{\theta}_{0}) \big) \Big) \\
&= 2 \Big( \mathcal{l}(y | \hat{\theta}_{S})  -  \mathcal{l}(y | \hat{\theta}_{0})  \Big)
\end{align}

where,    
- $\mathcal{l}(y | \hat{\theta}) \big)$ is the log likelihood of model with estimated parameters, $\hat{\theta}$]          
- $\hat{\theta}_{S}$ are parameters of a **saturated** model, $M_S$, with a parameter for each observation    
- Saturated model has the best possible fit to the training data        
- $\hat{\theta}_{0} parameters of model, $M_0$, to evaluate.   



## What is Deviance?


Fortunately, we can use the **deviance ratio** to compare models      

- Trick is to recognize that the log likelihood of the saturated model, $\mathcal{l}(y | \hat{\theta}_{0})$, is a constant:

$$D(y,\hat{\mu}) = Constant + 2 \mathcal{l}(y | \hat{\theta}_{0})$$

- Now the deviance ratio to compare two models, $M_1$ and $M_0$ is:   

\begin{align}
D(\hat{\theta}_1,\hat{\theta}_0) &= \frac{Constant + 2 \mathcal{l}(y | \hat{\theta}_{0})}{Constant + 2 \mathcal{l}(y | \hat{\theta}_{1})} \\ 
&= Constant + 2 \mathcal{l}(y | \hat{\theta}_{0}) - Constant - 2 \mathcal{l}(y | \hat{\theta}_{1}) \\
&= 2 \mathcal{l}(y | \hat{\theta}_{0}) - 2 \mathcal{l}(y | \hat{\theta}_{1})
\end{align}



## What is Deviance?

Can compare with **null model** with **null deviance**     

 - Unfortunately, this quantity is usually just called, deviance, but is actually null deviance  
- For large samples null deviance is Chi Squared distributed     

- Test statistical significance of the model against the null model using the Chi Squared test   
- Depends on  Wilk's theorem, and is referred to as **Wilk's test**. 

- Can comparing models with ratio of null deviance as well  


## Summary  

- Models with nonlinear response have non-Normal distributions  

- The generalized linear model accommodates nonlinear response distributions          

- Link function transforms to linear model       
   - Inverse link function transforms from Normal distribution to response distribution   

- Evaluating Binomial response models    
   - Confusion matrix organizes 
   - Compute metrics from elements of confusion matrix
   - Use multiple evaluation criteria 

- Compare model performance with deviance   

